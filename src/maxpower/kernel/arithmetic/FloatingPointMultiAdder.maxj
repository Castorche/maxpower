package maxpower.kernel.arithmetic;

import static com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFETypeFactory.dfeBool;
import static com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFETypeFactory.dfeFloat;
import static com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFETypeFactory.dfeInt;
import static com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFETypeFactory.dfeRawBits;
import static com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFETypeFactory.dfeUInt;
import static com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEStructType.sft;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import maxpower.kernel.KernelBinaryOp.Max;
import maxpower.kernel.TreeReduce;
import maxpower.kernel.pipeline.FanoutLimiter;
import maxpower.ops.AssociativeOp;

import com.maxeler.maxcompiler.v2.errors.MaxCompilerAPIError;
import com.maxeler.maxcompiler.v2.kernelcompiler.KernelLib;
import com.maxeler.maxcompiler.v2.kernelcompiler.SMIO;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.Bitops;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.FloatingPoint;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEFloat;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEType;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEVar;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEStruct;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEStructType;
import com.maxeler.maxcompiler.v2.statemachine.DFEsmInput;
import com.maxeler.maxcompiler.v2.statemachine.DFEsmOutput;
import com.maxeler.maxcompiler.v2.statemachine.DFEsmValue;
import com.maxeler.maxcompiler.v2.statemachine.kernel.KernelStateMachine;
import com.maxeler.maxcompiler.v2.statemachine.types.DFEsmValueType;
import com.maxeler.maxcompiler.v2.utils.MathUtils;

/**
 * Add several floating-point numbers, without de-normalizing and re-normalizing the intermediate results,
 * thus saving resources.
 *
 * N.B. The addition will be performed in a binary tree, which may slightly effect the final result, due
 * to the altered order of the additions (floating-point addition is not strictly commutative).
 */
public class FloatingPointMultiAdder {
	public static DFEVar add(int numGuardBits, DFEVar... summands) {
		return add(numGuardBits, Arrays.asList(summands));
	}

	public static DFEVar add(int numGuardBits, List<DFEVar> summands) {
		switch (summands.size()) {
		case 0: throw new MaxCompilerAPIError("Must have at least one float.");
		case 1: return summands[0];
		case 2: return summands[0] + summands[1];
		default: ; // continue
		}

		checkTypesIdentical(summands);

		KernelLib owner = summands[0].getKernel();
		DFEFloat  type  = (DFEFloat) summands[0].getType();
		DFEVar maxExponent = getMaxExponent(summands);

		List<DFEStruct> treeValues = getReductionInputs(numGuardBits, summands, maxExponent);

		DFEStruct sum = TreeReduce.reduce(new CondAddSubWithBitGrowth(), treeValues);
		DFEVar sumNeg = sum["neg"];
		DFEVar sumVal = sum["val"];

		// Fix the signs of the result after the reduction
		int sumValBits = sumVal.getType().getTotalBits();
		sumNeg ^= sumVal.slice(sumValBits-1);
		sumVal  = sumVal.slice(sumValBits-1) ? -sumVal : sumVal;

		int exponent_size = maxExponent.getType().getTotalBits();
		int mantissa_size = type.getMantissaBits() - 1;

		DFEVar leading_one = getLeadingOnePosition(sumVal).cast(maxExponent.getType());

		DFEVar is_zero = sumVal.eq(0);

		// Check that the amount that we have to shift to the left is not greater than the maximum exponent. If that were the case,
		// we have underflow happening.
		DFEVar is_underflow = maxExponent.cast(dfeUInt(16)) + leading_one.cast(dfeUInt(16)) <= mantissa_size + numGuardBits;

		DFEVar incorrect_result = is_zero | is_underflow;

		DFEVar result_exponent = maxExponent + (leading_one - mantissa_size - numGuardBits);

		sumVal = sumVal << (sumValBits - leading_one).cast(dfeUInt(MathUtils.bitsToAddress(sumValBits)));

		// Use guard bits to round
		if (numGuardBits > 0) {
			// Add a bit to the left to check for overflow
			DFEVar result_mantissa_overflow= (owner.constant.var(false) # sumVal).cast(dfeUInt(sumValBits+1));

			DFEVar result_mantissa_extended_rounded = result_mantissa_overflow + (1 << ((sumValBits - mantissa_size) - 1));

			DFEVar overflow = result_mantissa_extended_rounded[sumValBits];

			result_exponent = overflow ? result_exponent + 1 : result_exponent;

			sumVal = result_mantissa_extended_rounded.slice(0, sumValBits);
		}

		DFEVar result_mantissa = sumVal.slice(sumValBits-mantissa_size, mantissa_size).cast(dfeUInt(mantissa_size));

		result_exponent = incorrect_result ? 0 : result_exponent;
		result_mantissa = incorrect_result ? 0 : result_mantissa;

		return (sumNeg # result_exponent # result_mantissa).cast(dfeFloat(exponent_size, mantissa_size+1));
	}

	private static DFEVar getLeadingOnePosition(DFEVar v) {
		int bits = v.getType().getTotalBits();
		return Bitops.onehotDecode(Bitops.leading1Detect(v.cast(dfeRawBits(bits)).cast(dfeUInt(bits))));
	}

	private static DFEVar getMaxExponent(List<DFEVar> summands) {
		KernelLib owner = summands[0].getKernel();

		List<DFEVar> exponents = new ArrayList<DFEVar>();
		for (DFEVar summand : summands) {
			exponents.add(getExponent(summand));
		}

		// TODO this seems rather arbitrary
		int fanoutLimit = (owner.optimization.getPipeliningFactor() == 0)
		                ? 1024 : (8 + (int)((1 - owner.optimization.getPipeliningFactor())*8));
		return new FanoutLimiter(owner, TreeReduce.reduce(new Max(), exponents), fanoutLimit).get();
	}

	private static DFEVar getSign(DFEVar val) {
		return FloatingPoint.getSignBit(val).cast(dfeUInt(1));
	}

	private static DFEVar getExponent(DFEVar val) {
		int numExponentBits = ((DFEFloat) val.getType()).getExponentBits();
		return FloatingPoint.getExponentBits(val).cast(dfeUInt(numExponentBits));
	}

	// get mantissas with implicit leading 1 and guard bits appended
	private static DFEVar getMantissa(int numGuardBits, DFEVar val) {
		KernelLib owner = val.getKernel();
		DFEVar implicit1 = (getExponent(val) !== 0);
		DFEVar mantissa  = implicit1 # FloatingPoint.getMantissaBits(val);

		if (numGuardBits > 0)
			mantissa = mantissa # owner.constant.zero(dfeUInt(numGuardBits));

		return mantissa.cast(dfeUInt(mantissa.getType().getTotalBits()));
	}

	private static DFEVar getShift(DFEVar maxExponent, DFEVar summand, int maxShiftBits) {
		DFEVar shift = maxExponent - getExponent(summand);

		// it is slightly cheaper to check the top bits of the shift that do a comparison
		// TODO will they not optimize to exactly the same thing?
		int shiftMsbBits = shift.getType().getTotalBits() - maxShiftBits;
		DFEVar shiftMsb = shift.slice(maxShiftBits, shiftMsbBits).cast(dfeUInt(shiftMsbBits));

		return (shiftMsb === 0) ? shift.cast(dfeUInt(maxShiftBits)) : ((1<<maxShiftBits) - 1);
	}

	private static List<DFEStruct> getReductionInputs(int numGuardBits, List<DFEVar> summands, DFEVar maxExponent) {
		KernelLib owner = summands[0].getKernel();

		List<DFEStruct> redVals = new ArrayList<DFEStruct>();
		for (DFEVar summand : summands) {
			DFEVar mantissa     = getMantissa(numGuardBits, summand);
			int    maxShiftBits = MathUtils.bitsToRepresent(mantissa.getType().getTotalBits());
			DFEVar normalized   = (mantissa >> getShift(maxExponent, summand, maxShiftBits));

			DFEVar zeroBit  = owner.constant.zero(dfeUInt(1));
			DFEVar redValue = (zeroBit # normalized).cast(dfeInt(normalized.getType().getTotalBits()+1));

			DFEStruct redVal = getReductionType(redValue.getType()).newInstance(owner);
			redVal["neg"] <== getSign(summand);
			redVal["val"] <== redValue;

			redVals.add(redVal);
		}
		return redVals;
	}

	private static void checkTypesIdentical(List<DFEVar> summands) {
		for (DFEVar summand : summands) {
			if (!summand.getType().equals(summands[0].getType())) {
				throw new MaxCompilerAPIError("All of the floats must have the same type.");
			}
		}
	}

	private static DFEStructType getReductionType(DFEType valueType) {
		return new DFEStructType(sft("neg", dfeBool()), sft("val", valueType));
	}

	// The CondAddSub pass in the compiler does not currently support bit growth.
	// This is temporary workaround until it does.
	private static class CondAddSubWithBitGrowth implements AssociativeOp<DFEStruct> {
		// Implement using state machine so we're not unnecessarily creating extra nodes in graph.
		private static class SM extends KernelStateMachine {
			private final DFEsmInput a, b, c;
			private final DFEsmOutput r;

			protected SM(KernelLib owner, int aBits, int bBits) {
				super(owner);

				a = io.input("a", dfeInt(aBits));
				b = io.input("b", dfeInt(bBits));
				c = io.input("c", dfeBool());
				r = io.output("r", dfeInt(Math.max(aBits, bBits)+1));
			}

			@Override
			protected void outputFunction() {
				r <== a.cast(r.getType()) + ((b ^ mask(c, b.getType())) + c.cast(b.getType())).cast(r.getType());
			}

			private DFEsmValue mask(DFEsmValue c, DFEsmValueType type) {
				DFEsmValue mask = c;
				for (int i = 1; i < type.getTotalBits(); ++i) {
					mask = mask # c;
				}
				return mask.cast(type);
			}

			@Override protected void nextState() {} // there is no state!!
		}

		private static int i = 0;
		@Override
		public DFEStruct op(DFEStruct a, DFEStruct b) {
			DFEVar aNeg = a["neg"];
			DFEVar bNeg = b["neg"];
			DFEVar aVal = a["val"];
			DFEVar bVal = b["val"];

			KernelLib owner = a.getKernel();

			int aBits = aVal.getType().getTotalBits();
			int bBits = bVal.getType().getTotalBits();

			SMIO sm = owner.addStateMachine("CondAddSubSM"+i++, new SM(owner, aBits, bBits));
			sm.connectInput("a", aVal);
			sm.connectInput("b", bVal);
			sm.connectInput("c", aNeg ^ bNeg);

			DFEStruct result = getReductionType(sm.getOutput("r").getType()).newInstance(a.getKernel());
			result["neg"] <== aNeg;
			result["val"] <== sm.getOutput("r");
			return result;
		}
	}
}
